# Sense+
## What is Sense+
Our program integrates voice and facial recognition to detect an individual’s emotions.

The voice using sentiment analysis to detect keywords from an audio transcript. These keywords are categorised as neutral, positive or negative. Natural language processing and regular expressions are utilised to break down audio transcripts into multiple sentences/segments. 

The facial recognition uses convolutional neural networks to pick up features of ones faces, to identify emotions. Videos broken down into multiple frames which are fed into neutral network to make the predication.

This model is trained and validated using Facial Expression Recognition data sense from Kaggle 2013. 
#### As a disclaimer this is not representative of the final vision of our product more so just a proof of concept. 


## Requirements
- AWS (S3, Lambda Function)
- Python (Keras, Tensorflow, Pandas, Numpy, Speech Recognition)
- Android Studio (Java)


## Idea
The global pandemic has revealed the growing issue and importance of mental health, in particular one’s accessibility to mental health services and the detection of someone possibly suffering from stress, anxiety or other mental health conditions. 

We personally have seen that being mentally well has improved our ability to work and study. (more on how good mental health is important for the productivity of society)

It is statistics such as young people are less likely to seek professional help or the societal stigma of seeking treatment that worries us. 
Our proof of concept aims to make the process of helping those proactive in identifying suffering individuals, all whilst aiding to reduce stigma, rather than waiting for individuals to come forward by themselves. 


## Potential
Customers could include companies looking to monitor the mental well being of their employees to boost productivity. In a controlled environment employee could undertake interviews or in the future the product could be implemented passively to monitor the mental health of employees concurrently at work. This could heavily aid the company in identifying 


## Author
Gideon Teo Zhi Kai, Darren Tan, Jeslyn Teo Wen Qii, Harrison Crawford Sloan, Nick Sum Yew Fei
